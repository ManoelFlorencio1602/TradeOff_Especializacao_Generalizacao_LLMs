{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b97b663-83c6-4a88-8857-dc1765827aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c15ef-11ae-4124-a557-8e07f22d3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..'\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c98f92-146e-421e-aeb0-da5e15e9df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "astronomy_df = pd.read_csv('mmlu_data/astronomy_questions.csv')\n",
    "econometrics_df = pd.read_csv('mmlu_data/econometrics_questions.csv')\n",
    "world_religions_df = pd.read_csv('mmlu_data/world_religions_questions.csv')\n",
    "complete_questionnaire = pd.concat([astronomy_df, econometrics_df, world_religions_df])\n",
    "print(complete_questionnaire.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bef26e-f283-469c-96b9-76d707b7a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_base_answers = np.load('answers/llama3-8b-base-MMLU-answers.npy')\n",
    "llama_LR1e4_answers = np.load('answers/llama3-8b-LR1e4-MMLU-answers.npy')\n",
    "llama_LR5e5_answers = np.load('answers/llama3-8b-LR5e5-MMLU-answers.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbf40dd-36bf-460f-9171-c6211757473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_questionnaire['base_answers'] = llama_base_answers\n",
    "complete_questionnaire['LR1e4_answers'] = llama_LR1e4_answers\n",
    "complete_questionnaire['LR5e5_answers'] = llama_LR5e5_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d1819a-082c-424e-a7ea-4f811f9502f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>subject</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>base_answers</th>\n",
       "      <th>LR1e4_answers</th>\n",
       "      <th>LR5e5_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You've made a scientific theory that there is ...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['When you and many other Jedi have tested the...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One astronomical unit (AU) is equal to approxi...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['130 million km', '150 million km', '170 mill...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most rocks on the Moon's surface are older tha...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['Lunar rocks are composed of fragments pulver...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why can't we see the Sun's corona except durin...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>[\"The corona is made up mostly of charged part...</td>\n",
       "      <td>3</td>\n",
       "      <td>3\\n\\n``</td>\n",
       "      <td></td>\n",
       "      <td>Answer should</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What type of radiation causes a black hole to ...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['Schwarzschild radiation', 'Planck radiation'...</td>\n",
       "      <td>3</td>\n",
       "      <td>3\\n\\nAnswer</td>\n",
       "      <td>3</td>\n",
       "      <td>_______________________</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question    subject  \\\n",
       "0  You've made a scientific theory that there is ...  astronomy   \n",
       "1  One astronomical unit (AU) is equal to approxi...  astronomy   \n",
       "2  Most rocks on the Moon's surface are older tha...  astronomy   \n",
       "3  Why can't we see the Sun's corona except durin...  astronomy   \n",
       "4  What type of radiation causes a black hole to ...  astronomy   \n",
       "\n",
       "                                             choices  answer base_answers  \\\n",
       "0  ['When you and many other Jedi have tested the...       2            2   \n",
       "1  ['130 million km', '150 million km', '170 mill...       1            1   \n",
       "2  ['Lunar rocks are composed of fragments pulver...       1            1   \n",
       "3  [\"The corona is made up mostly of charged part...       3      3\\n\\n``   \n",
       "4  ['Schwarzschild radiation', 'Planck radiation'...       3  3\\n\\nAnswer   \n",
       "\n",
       "  LR1e4_answers            LR5e5_answers  \n",
       "0             2                        2  \n",
       "1             1                        1  \n",
       "2             1                      ```  \n",
       "3                          Answer should  \n",
       "4             3  _______________________  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_questionnaire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f63847-62a9-4c7c-aeb4-126b548e1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_questionnaire.to_csv('answers/answered_MMLU_questionnaire.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f032ffb5-a879-403d-927a-10043b7625d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>subject</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "      <th>base_answers</th>\n",
       "      <th>LR1e4_answers</th>\n",
       "      <th>LR5e5_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You've made a scientific theory that there is ...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['When you and many other Jedi have tested the...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One astronomical unit (AU) is equal to approxi...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['130 million km', '150 million km', '170 mill...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most rocks on the Moon's surface are older tha...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['Lunar rocks are composed of fragments pulver...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why can't we see the Sun's corona except durin...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>[\"The corona is made up mostly of charged part...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What type of radiation causes a black hole to ...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>['Schwarzschild radiation', 'Planck radiation'...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>_______________________</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question    subject  \\\n",
       "0  You've made a scientific theory that there is ...  astronomy   \n",
       "1  One astronomical unit (AU) is equal to approxi...  astronomy   \n",
       "2  Most rocks on the Moon's surface are older tha...  astronomy   \n",
       "3  Why can't we see the Sun's corona except durin...  astronomy   \n",
       "4  What type of radiation causes a black hole to ...  astronomy   \n",
       "\n",
       "                                             choices  answer base_answers  \\\n",
       "0  ['When you and many other Jedi have tested the...       2            2   \n",
       "1  ['130 million km', '150 million km', '170 mill...       1            1   \n",
       "2  ['Lunar rocks are composed of fragments pulver...       1            1   \n",
       "3  [\"The corona is made up mostly of charged part...       3            3   \n",
       "4  ['Schwarzschild radiation', 'Planck radiation'...       3            3   \n",
       "\n",
       "  LR1e4_answers            LR5e5_answers  \n",
       "0             2                        2  \n",
       "1             1                        1  \n",
       "2             1                      ```  \n",
       "3           NaN                      NaN  \n",
       "4             3  _______________________  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_questionnaire = pd.read_csv('answers/answered_MMLU_questionnaire_clean.csv')\n",
    "complete_questionnaire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32ddb753-ade5-491b-a832-9aa02a6a1a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': '62.67%', 'LR1e4': '56.67%', 'LR5e5': '53.33%'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['base','LR1e4','LR5e5']\n",
    "general_correct_answers = {key: 0 for key in model_names}\n",
    "\n",
    "for i in range(len(complete_questionnaire)):\n",
    "    \n",
    "    expected_answer = str(complete_questionnaire.iloc[i, 3])\n",
    "    base_answer = complete_questionnaire.iloc[i, 4]\n",
    "    lr1e4_answer = complete_questionnaire.iloc[i, 5]\n",
    "    lr5e5_answer = complete_questionnaire.iloc[i, 6]\n",
    "\n",
    "    if(base_answer == expected_answer):\n",
    "        general_correct_answers['base'] += 1\n",
    "    if(lr1e4_answer == expected_answer):\n",
    "        general_correct_answers['LR1e4'] += 1\n",
    "    if(lr5e5_answer == expected_answer):\n",
    "        general_correct_answers['LR5e5'] += 1\n",
    "\n",
    "general_correct_answers = {key: f'{round(value/len(complete_questionnaire) * 100, 2)}%' for key, value in general_correct_answers.items()}\n",
    "general_correct_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "904d9905-ca07-411b-99ac-33b4e6dad217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': {'STEM': '64.0%',\n",
       "  'Humanidades': '34.0%',\n",
       "  'Ciências Sociais': '90.0%'},\n",
       " 'LR1e4': {'STEM': '54.0%',\n",
       "  'Humanidades': '48.0%',\n",
       "  'Ciências Sociais': '68.0%'},\n",
       " 'LR5e5': {'STEM': '42.0%',\n",
       "  'Humanidades': '40.0%',\n",
       "  'Ciências Sociais': '78.0%'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['base','LR1e4','LR5e5']\n",
    "domains = ['STEM','Humanidades','Ciências Sociais']\n",
    "\n",
    "domain_specific_correct_answers = {model_name: {domain: 0 for domain in domains} for model_name in model_names}\n",
    "domain_specific_correct_answers\n",
    "for i in range(len(complete_questionnaire)):\n",
    "    if(i < 50):\n",
    "        domain = 'STEM'\n",
    "    elif(i >= 50 and i < 100):\n",
    "        domain = 'Humanidades'\n",
    "    else:\n",
    "        domain = 'Ciências Sociais'\n",
    "    \n",
    "    expected_answer = str(complete_questionnaire.iloc[i, 3])\n",
    "    base_answer = complete_questionnaire.iloc[i, 4]\n",
    "    lr1e4_answer = complete_questionnaire.iloc[i, 5]\n",
    "    lr5e5_answer = complete_questionnaire.iloc[i, 6]\n",
    "\n",
    "    if(base_answer == expected_answer):\n",
    "        domain_specific_correct_answers['base'][domain] += 1\n",
    "    if(lr1e4_answer == expected_answer):\n",
    "        domain_specific_correct_answers['LR1e4'][domain] += 1\n",
    "    if(lr5e5_answer == expected_answer):\n",
    "        domain_specific_correct_answers['LR5e5'][domain] += 1\n",
    "\n",
    "domain_specific_correct_answers = {model_name: {domain: f'{round(value/50 * 100, 2)}%' for domain, value in domain_specific_correct_answers[model_name].items()} for model_name in domain_specific_correct_answers.keys()}\n",
    "domain_specific_correct_answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
